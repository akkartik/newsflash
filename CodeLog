=-=1 - Wed Jan 14 18:32:20 PST 2009
Simple URL download.
=-=2 - Sat Jan 17 12:01:03 PST 2009
Download all URLs.
=-=3 - Sat Jan 17 13:39:41 PST 2009
No need for a download step. Just use feedparser.
=-=4 - Sat Jan 17 14:00:45 PST 2009
Setup task to import feeds.
=-=5 - Sat Jan 17 15:40:19 PST 2009
Import feeds done. Now let's get it working on slicehost repo.
=-=6 - Mon Jan 19 20:35:19 PST 2009
Done.
=-=7 - Tue Jan 20 09:23:44 PST 2009

Remove id field.
=-=8 - Tue Jan 20 10:05:54 PST 2009
Turns out we do need id field for yaml fixtures.
=-=9 - Tue Jan 20 10:42:30 PST 2009

Bugfix: get contents from crawled feeds.
=-=10 - Tue Jan 20 10:47:36 PST 2009

Hyp: "execution expired' is because of Timeout::Error:
  http://www.slashdotdash.net/2008/02/15/ruby-tidbit-timeout-code-execution
=-=11 - Tue Jan 20 18:31:32 PST 2009
=-=12 - Tue Jan 20 18:35:16 PST 2009

Feed crawler still not working properly - title and content of all feeds is
borked.
It's becoming clear that's where all the complexity is. The front-end is easy.
=-=15 - Wed Jan 21 10:52:54 PST 2009
Turns out most of the misbehaving feeds are atom - we aren't handling atom
feeds properly.
Some others have content but seemingly no permalink.
I did this triage on the air.
=-=16 - Wed Jan 21 19:12:17 PST 2009
=-=17 - Wed Jan 21 19:12:39 PST 2009
Now we know how to handle atom feeds.
=-=18 - Wed Jan 21 20:05:24 PST 2009
Descriptions are sometimes not getting parsed right. File encoding issues,
perhaps.
=-=19 - Wed Jan 21 20:42:54 PST 2009
Cleanup.
=-=20 - Wed Jan 21 20:52:27 PST 2009
=-=21 - Wed Jan 21 21:03:10 PST 2009
Reverse the feed entries - that way we only need to sort by id descending
within a feed, and diversity means we don't care about parsing times,
timezones, any of that crap.
=-=22 - Thu Jan 22 07:22:30 PST 2009
Feed crawler daemonified.
=-=23 - Thu Jan 22 07:37:42 PST 2009
Standardized feed file location between slicehost and air.
=-=24 - Thu Jan 22 07:56:10 PST 2009

First-cut implementation for the workhorse homepage. No update yet, all it
does is show most recent post from first feed.
Already we find an error in our db schema and crawler.
=-=25 - Thu Jan 22 08:24:05 PST 2009
Back-end done for AJAX update. Not properly connected up with view yet.
=-=26 - Thu Jan 22 10:08:38 PST 2009
View connected up, but not updated yet. Should I really be using show for the
remote_link? Shouldn't it be update? Also need to set doneReading, and skip
posts we're doneReading, and retry next feedurl if this one has nothing.
=-=27 - Thu Jan 22 10:14:59 PST 2009
