=-=1 - Wed Jan 14 18:32:20 PST 2009
Simple URL download.
=-=2 - Sat Jan 17 12:01:03 PST 2009
Download all URLs.
=-=3 - Sat Jan 17 13:39:41 PST 2009
No need for a download step. Just use feedparser.
=-=4 - Sat Jan 17 14:00:45 PST 2009
Setup task to import feeds.
=-=5 - Sat Jan 17 15:40:19 PST 2009
Import feeds done. Now let's get it working on slicehost repo.
=-=6 - Mon Jan 19 20:35:19 PST 2009
Done.
=-=7 - Tue Jan 20 09:23:44 PST 2009

Remove id field.
=-=8 - Tue Jan 20 10:05:54 PST 2009
Turns out we do need id field for yaml fixtures.
=-=9 - Tue Jan 20 10:42:30 PST 2009

Bugfix: get contents from crawled feeds.
=-=10 - Tue Jan 20 10:47:36 PST 2009

Hyp: "execution expired' is because of Timeout::Error:
  http://www.slashdotdash.net/2008/02/15/ruby-tidbit-timeout-code-execution
=-=11 - Tue Jan 20 18:31:32 PST 2009
=-=12 - Tue Jan 20 18:35:16 PST 2009

Feed crawler still not working properly - title and content of all feeds is
borked.
It's becoming clear that's where all the complexity is. The front-end is easy.
=-=15 - Wed Jan 21 10:52:54 PST 2009
